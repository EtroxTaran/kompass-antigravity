version: '3.8'

# Optional Whisper service for local development on x86_64 hosts.
# Staging and production use an external Whisper/AI transcription API
# configured via WHISPER_API_URL (see docs/deployment/DEPLOYMENT_GUIDE.md).

services:
  whisper:
    image: onerahmet/openai-whisper-asr-webservice:latest-gpu
    container_name: kompass-whisper
    environment:
      - ASR_MODEL=${WHISPER_MODEL:-base}
      - ASR_ENGINE=openai_whisper
    ports:
      - '8001:9000' # API port
    volumes:
      - whisper-models:/root/.cache/whisper
    networks:
      - kompass-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:9000/health']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    # Note: This image requires x86_64 with CUDA for best performance.
    # Do not use this service on ARM-only hosts (e.g., Hetzner CAX ARM instances).
    # If GPU acceleration is available, you can enable it by adding:
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

networks:
  kompass-network:
    external: false

