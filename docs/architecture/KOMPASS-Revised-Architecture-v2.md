# KOMPASS Revised Architecture Document v2

**Version**: 2.0  
**Date**: 2025-11-12  
**Status**: Final  
**Authors**: Senior Architecture Team

---

## 1. Executive Summary & Core Principles

This document presents a pragmatic, phased architecture for the KOMPASS project, addressing the critical risks identified in the pre-mortem analysis while preserving the core value propositions of offline-first capability and GoBD compliance.

This revised architecture prioritizes **reliability, compliance, and incremental value delivery**. We will build a robust foundation with a simplified offline model and a dedicated, immutable audit log for GoBD compliance. Complexity will be introduced in later, distinct phases, ensuring the core product is stable and trustworthy from day one.

### Core Principles

-   **Validated Phased Approach**: The phased rollout (MVP → Analytics → Events → AI) is confirmed as the correct strategy to manage complexity and deliver value incrementally.
-   **Polyglot Persistence**: We will use the right database for the right job. The architecture is designed to evolve, incorporating different database technologies (PostgreSQL, Neo4j, Vector DB) as required, while maintaining a single source of truth for operational data in CouchDB.
-   **Simplicity First**: The initial focus is on a lean, reliable MVP that solves the user's most pressing problems. We will earn user trust with a stable core product before introducing advanced features.
-   **Compliance by Design**: GoBD and DSGVO compliance are not afterthoughts but are baked into the core architecture through an immutable audit log and clear data management policies.
-   **User-Centric Offline Experience**: The offline mode is designed to be seamless and automatic, removing cognitive load from the user. There will be no manual storage management.

## 2. Phase 1 (MVP) Architecture Deep Dive

The MVP will deliver the core CRM functionality with a reliable offline mode and guaranteed GoBD compliance. This phase is designed to be completed within 4 months with the available team.

### 2.1. GoBD Compliance: The Immutable Audit Log

To achieve absolute, provable immutability for GoBD, we will physically separate the operational data from the audit trail. A dedicated, append-only CouchDB database named `kompass-audit` will store a blockchain-style log of all changes to compliant-sensitive documents.

**Data Flow:**

The core principle is **"Audit-Then-Write"**. An operational data change is only committed after its corresponding audit log entry has been successfully and immutably stored.

1.  A CUD (Create, Update, Delete) operation is requested at a NestJS endpoint (e.g., `POST /api/v1/invoices`).
2.  The service validates the request and prepares the final JSON state of the operational document.
3.  A **SHA-256 hash** of this new document state (as a string) is calculated.
4.  The service retrieves the hash from the *most recent* audit entry for that `documentId`. This creates a cryptographic chain. For a new document, the `previousHash` is `null`.
5.  A new `AuditLog` document is created (see schema below). This document contains the new hash, the previous hash, and a **digital signature** (e.g., ECDSA) of the `newHash`, signed using a server-side private key to prove the log entry originated from our system.
6.  This `AuditLog` document is written to the `kompass-audit` database. This database will be configured at the database level to **forbid updates or deletes** using a `validate_doc_update` function.
7.  **Only after the audit log write is successful**, the operational document is saved to the primary `kompass-data` CouchDB database. This ensures that no data can exist without a corresponding, immutable audit entry.

**AuditLog Schema (`packages/shared/src/types/entities/audit-log.ts`):**

```typescript
interface ChangeDetail {
  field: string;
  oldValue: any;
  newValue: any;
}

interface AuditLog extends BaseEntity {
  _id: string; // Immutable UUID, generated by the system
  documentId: string; // The _id of the document in the operational database
  documentType: string; // e.g., 'invoice', 'customer'
  operation: 'CREATE' | 'UPDATE' | 'DELETE';
  timestamp: Date; // ISO 8601 timestamp of the event
  
  // Blockchain-style integrity chain
  hash: string; // SHA-256 hash of the new document state
  previousHash: string | null; // Hash from the previous AuditLog entry for this documentId
  
  // Verification
  signature: string; // Digital signature of the 'hash' field
  
  // User and context
  userId: string; // ID of the user performing the action
  
  // Detailed changes (for UPDATE operations)
  changes: ChangeDetail[];
}
```

### 2.2. Offline-First Strategy

To address the critical risks of data loss and user burden, the offline strategy is radically simplified. The user will not be required to manage storage manually.

-   **Automatic Tiering & Caching**: The PWA will automatically manage a ~50MB storage budget. Data is categorized into tiers and managed via an LRU (Least Recently Used) eviction policy for non-essential data.
    -   `essential` (5MB): User profile, their active customers, contacts. Always available.
    -   `recent` (10MB): Last 30 days of protocols, active opportunities. Cached via LRU.
    -   `onDemand` (35MB): User-triggered downloads (e.g., "Make Project XYZ available offline"). Cached via LRU.

-   **Conflict Resolution**: The system will handle over 90% of conflicts automatically.
    -   **Last-Write-Wins**: Default strategy for most metadata fields.
    -   **Merge-Concatenate**: For text fields like notes, changes will be appended with user/timestamp information.
    -   **Manual Review**: Only critical numerical or status fields (e.g., `opportunity.estimatedValue`, `invoice.status`) will be flagged for a simple user review, presenting a clear choice: "Keep your version (EUR 5,000) or server version (EUR 5,500)?".

-   **Browser Support & Mitigation**:
    -   **Primary Target**: Chrome/Edge on all platforms will provide the full, reliable PWA experience.
    -   **Secondary Target (Safari)**: Due to iOS's 7-day data eviction policy, Safari users will see a persistent but dismissible banner: *"For the best offline experience and to prevent potential data loss after 7 days of inactivity, we recommend adding this app to your home screen."* The app remains fully functional, but the risk is made transparent.

### 2.3. Offline Data Schema (< 10MB Target)

To guarantee a fast initial sync and stay well within storage limits, the default offline dataset for a typical user is designed to be under 10MB.

-   **Customers** (`~2MB`): Up to 2000 records owned by or recently interacted with by the user.
    -   *Fields*: `_id`, `companyName`, `vatNumber`, `rating`, `owner`, `billingAddress`.
-   **Contacts** (`~2MB`): Up to 4000 records linked to the synced customers.
    -   *Fields*: `_id`, `customerId`, `firstName`, `lastName`, `email`, `phone`.
-   **Protocols** (`~3MB`): All protocol records from the last 30 days.
    -   *Fields*: `_id`, `customerId`, `date`, `title`, `content` (plain text, limited to 5000 chars to save space).
-   **Active Opportunities** (`~0.2MB`): Up to 200 active records.
    -   *Fields*: `_id`, `customerId`, `name`, `estimatedValue`, `probability`, `status`.
-   **Tasks/Appointments** (`~0.1MB`): Today's and the next 7 days' agenda.
-   **Total Estimated Size**: **~7.3MB**, leaving a healthy buffer for on-demand data and future growth.

---

## 3. Technology Choices & Justification

Technology choices are made to reduce complexity in early phases while enabling scalability.

-   **Event Streaming (Phase 3)**: We will use **RabbitMQ**. It is more lightweight to operate and manage than Apache Kafka, and its flexible routing models (e.g., topic, direct exchanges) are perfectly suited for the project's initial eventing needs (notifications, webhooks, inter-service communication). This choice reduces the significant operational overhead associated with managing a Kafka/Zookeeper cluster, which is not justified for the MVP's requirements.

-   **Data Replication (Phase 2)**: A **custom NestJS microservice** will be developed to handle the one-way data replication from CouchDB's `_changes` feed to the PostgreSQL analytics database. This provides maximum control over data transformation, schema mapping, error handling (including a dead-letter queue), and resilience, which is preferable to the potential rigidity of an off-the-shelf ETL tool.

---

## 4. Observability & Monitoring

A robust observability stack is critical for diagnosing issues in a distributed, offline-first system.

-   **Logging**: All services (backend, replication) will use **Pino** for structured JSON logging. Logs will be aggregated in a central platform (e.g., Grafana Loki). Every log entry MUST contain a `correlationId` to trace a single user request across all services.
-   **Metrics**: Services will expose key operational metrics (e.g., request latency, error rates, queue depths, sync duration) via a `/metrics` endpoint in Prometheus format. **Grafana** will be used for dashboards and alerting.
-   **Tracing**: **OpenTelemetry** will be integrated into the NestJS backend and frontend to provide distributed tracing, allowing developers to visualize the entire lifecycle of a request, from a user click to database commit and subsequent event publishing.
-   **Frontend Monitoring**: **Sentry** will be implemented in the React PWA to capture real-world performance data, unhandled exceptions, and specific offline-related errors (e.g., sync failures, quota issues) directly from user devices.

---

## 5. Migration Strategy

The transition from the current architecture will be managed incrementally to minimize disruption.

1.  **Freeze Feature Development**: All work on new features in the current system is halted to establish a stable migration baseline.
2.  **Deploy Audit Log (Highest Priority)**: The `kompass-audit` database and the "Audit-Then-Write" pattern will be implemented and deployed first. All new data changes will immediately be compliant.
3.  **Backfill Audit Trail**: A one-time migration script will be run to read all existing GoBD-relevant documents, generate their hashes, and create the initial `AuditLog` entries with a special "migration" operation type.
4.  **Refactor Services**: Each NestJS service will be refactored one by one to use the new repository pattern that enforces the "Audit-Then-Write" flow.
5.  **Simplify PWA**: The frontend will be updated to remove all manual storage management UI. The new automatic, tiered caching strategy will be implemented, and the Safari-specific warning banner will be added.

---

## 6. Risk Mitigation & Conclusion

This revised architecture directly addresses the concerns raised in the pre-mortem analysis while retaining the project's core competitive advantages.

-   **Storage Complexity → Addressed**: Replaced with an automatic, user-transparent caching system.
-   **Data Loss Risk → Addressed**: Mitigated through continuous background sync, clear communication to Safari users, and server-side backups of all changes via the audit log.
-   **GoBD Compliance → Addressed**: Solved with a physically separate, immutable audit log that provides a provably unchangeable history, superior to application-level logic on a mutable database.
-   **Architectural Complexity → Addressed**: Managed via a phased approach where each new component adds distinct, measurable value.
-   **User Trust → Addressed**: By starting with a simple, reliable, and performant core product, we will build the trust necessary for the adoption of more advanced features in the future.

This architecture provides a clear and achievable path to delivering a successful MVP that is compliant, reliable, and loved by its users, while laying a scalable foundation for the long-term product vision.
